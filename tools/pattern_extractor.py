#!/usr/bin/env python3
"""
Skill-0 æ¨¡å¼æå–å·¥å…·
å¾å¤šå€‹ skills ä¸­æ­¸ç´å…±é€šæ¨¡å¼ï¼Œå»ºç«‹æ¨¡å¼åº«
"""

import json
import re
from pathlib import Path
from collections import Counter, defaultdict
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass, field
from datetime import datetime


@dataclass
class Pattern:
    """æ­¸ç´å‡ºçš„æ¨¡å¼"""
    id: str
    name: str
    description: str
    pattern_type: str  # action_sequence, rule_group, structure
    structure: Dict[str, Any] = field(default_factory=dict)
    found_in: List[str] = field(default_factory=list)
    frequency: float = 0.0
    examples: List[Dict] = field(default_factory=list)


class PatternExtractor:
    """æ¨¡å¼æå–å™¨"""
    
    def __init__(self, parsed_dir: str):
        self.parsed_dir = Path(parsed_dir)
        self.skills: List[Dict] = []
        self.patterns: List[Pattern] = []
        
    def load_skills(self) -> int:
        """è¼‰å…¥æ‰€æœ‰å·²è§£æçš„ skills"""
        self.skills = []
        
        for json_file in self.parsed_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    skill_data = json.load(f)
                    skill_data['_source_file'] = json_file.stem
                    self.skills.append(skill_data)
            except Exception as e:
                print(f"âš ï¸ è¼‰å…¥å¤±æ•— {json_file.name}: {e}")
                
        return len(self.skills)
    
    def extract_all_patterns(self) -> List[Pattern]:
        """æå–æ‰€æœ‰é¡å‹çš„æ¨¡å¼"""
        self.patterns = []
        
        # 1. æå–å‹•ä½œé¡å‹æ¨¡å¼
        self._extract_action_type_patterns()
        
        # 2. æå– directive é¡å‹æ¨¡å¼
        self._extract_directive_patterns()
        
        # 3. æå–çµæ§‹æ¨¡å¼ (action-rule çµ„åˆ)
        self._extract_structure_patterns()
        
        # 4. æå–æè¿°æ–‡å­—æ¨¡å¼ (é—œéµå­—)
        self._extract_keyword_patterns()
        
        return self.patterns
    
    def _extract_action_type_patterns(self):
        """æå–å¸¸è¦‹çš„ action é¡å‹çµ„åˆ"""
        # æ”¶é›†æ¯å€‹ skill çš„ action_type é›†åˆ
        skill_action_sets: Dict[str, Set[str]] = {}
        
        for skill in self.skills:
            meta = skill.get('meta', {})
            skill_id = meta.get('skill_id', skill.get('skill_id', skill.get('_source_file')))
            action_types = set()
            
            # æ”¯æ´ v2.0 schema çµæ§‹
            decomposition = skill.get('decomposition', {})
            actions = decomposition.get('actions', [])
            
            # ä¹Ÿæ”¯æ´èˆŠçš„ elements æ ¼å¼
            if not actions:
                actions = [e for e in skill.get('elements', []) if e.get('type') == 'action']
            
            for elem in actions:
                action_types.add(elem.get('action_type', 'unknown'))
            
            if action_types:
                skill_action_sets[skill_id] = action_types
        
        # æ‰¾å‡ºå…±é€šçš„ action çµ„åˆ
        if len(skill_action_sets) < 2:
            return
            
        # è¨ˆç®—æ¯å° action_type çš„å…±ç¾é »ç‡
        cooccurrence = Counter()
        for skill_id, actions in skill_action_sets.items():
            action_list = sorted(actions)
            for i, a1 in enumerate(action_list):
                for a2 in action_list[i+1:]:
                    cooccurrence[(a1, a2)] += 1
        
        # å»ºç«‹æ¨¡å¼
        for (a1, a2), count in cooccurrence.most_common(10):
            if count >= 2:  # è‡³å°‘å‡ºç¾åœ¨ 2 å€‹ skills
                found_skills = [
                    sid for sid, actions in skill_action_sets.items()
                    if a1 in actions and a2 in actions
                ]
                
                pattern = Pattern(
                    id=f"pat_act_{a1}_{a2}",
                    name=f"{a1} + {a2} çµ„åˆ",
                    description=f"åŒæ™‚åŒ…å« {a1} å’Œ {a2} é¡å‹çš„å‹•ä½œ",
                    pattern_type="action_combination",
                    structure={"action_types": [a1, a2]},
                    found_in=found_skills,
                    frequency=count / len(skill_action_sets)
                )
                self.patterns.append(pattern)
    
    def _extract_directive_patterns(self):
        """æå– directive ä½¿ç”¨æ¨¡å¼"""
        directive_by_type = defaultdict(list)
        
        for skill in self.skills:
            meta = skill.get('meta', {})
            skill_id = meta.get('skill_id', skill.get('skill_id', skill.get('_source_file')))
            
            # æ”¯æ´ v2.0 schema çµæ§‹
            decomposition = skill.get('decomposition', {})
            directives = decomposition.get('directives', [])
            
            # ä¹Ÿæ”¯æ´èˆŠçš„ elements æ ¼å¼
            if not directives:
                directives = [e for e in skill.get('elements', []) if e.get('type') == 'directive']
            
            for elem in directives:
                dtype = elem.get('directive_type', 'unknown')
                directive_by_type[dtype].append({
                    'skill': skill_id,
                    'description': elem.get('description', '')[:100]
                })
        
        # ç‚ºæ¯ç¨®å¸¸è¦‹çš„ directive é¡å‹å»ºç«‹æ¨¡å¼
        for dtype, items in directive_by_type.items():
            if len(items) >= 1:
                pattern = Pattern(
                    id=f"pat_dir_{dtype}",
                    name=f"Directive: {dtype}",
                    description=f"ä½¿ç”¨ {dtype} é¡å‹çš„ directive",
                    pattern_type="directive_usage",
                    structure={"directive_type": dtype},
                    found_in=list(set(item['skill'] for item in items)),
                    frequency=len(items) / len(self.skills) if self.skills else 0,
                    examples=items[:3]
                )
                self.patterns.append(pattern)
    
    def _extract_structure_patterns(self):
        """æå–çµæ§‹æ¨¡å¼ (å…ƒç´ çµ„åˆ)"""
        # åˆ†ææ¯å€‹ skill çš„å…ƒç´ æ¯”ä¾‹
        structures = []
        
        for skill in self.skills:
            meta = skill.get('meta', {})
            skill_id = meta.get('skill_id', skill.get('skill_id', skill.get('_source_file')))
            
            # æ”¯æ´ v2.0 schema çµæ§‹
            decomposition = skill.get('decomposition', {})
            elements = (
                decomposition.get('actions', []) + 
                decomposition.get('rules', []) + 
                decomposition.get('directives', [])
            )
            
            # ä¹Ÿæ”¯æ´èˆŠçš„ elements æ ¼å¼
            if not elements:
                elements = skill.get('elements', [])
            
            # ç‚ºå…ƒç´ æ·»åŠ  type æ¨™è¨˜ (v2.0 æ ¼å¼ä¸­éœ€è¦æ ¹æ“šä¾†æºåˆ¤æ–·)
            counts = Counter()
            for e in decomposition.get('actions', []):
                counts['action'] += 1
            for e in decomposition.get('rules', []):
                counts['rule'] += 1
            for e in decomposition.get('directives', []):
                counts['directive'] += 1
            
            # èˆŠæ ¼å¼
            if not counts:
                counts = Counter(e.get('type') for e in elements)
            
            total = sum(counts.values())
            
            if total > 0:
                structure = {
                    'skill': skill_id,
                    'action_ratio': counts.get('action', 0) / total,
                    'rule_ratio': counts.get('rule', 0) / total,
                    'directive_ratio': counts.get('directive', 0) / total,
                    'total': total
                }
                structures.append(structure)
        
        # è­˜åˆ¥çµæ§‹é¡å‹
        action_heavy = [s for s in structures if s['action_ratio'] > 0.6]
        rule_heavy = [s for s in structures if s['rule_ratio'] > 0.4]
        balanced = [s for s in structures if 0.2 <= s['action_ratio'] <= 0.5 
                   and 0.2 <= s['rule_ratio'] <= 0.5]
        
        if action_heavy:
            self.patterns.append(Pattern(
                id="pat_struct_action_heavy",
                name="å‹•ä½œå°å‘çµæ§‹",
                description="ä»¥ action ç‚ºä¸»çš„ skillï¼Œå‹•ä½œä½”æ¯”è¶…é 60%",
                pattern_type="structure",
                structure={"dominant": "action", "ratio_threshold": 0.6},
                found_in=[s['skill'] for s in action_heavy],
                frequency=len(action_heavy) / len(structures) if structures else 0
            ))
        
        if rule_heavy:
            self.patterns.append(Pattern(
                id="pat_struct_rule_heavy",
                name="è¦å‰‡å°å‘çµæ§‹",
                description="ä»¥ rule ç‚ºä¸»çš„ skillï¼Œè¦å‰‡ä½”æ¯”è¶…é 40%",
                pattern_type="structure",
                structure={"dominant": "rule", "ratio_threshold": 0.4},
                found_in=[s['skill'] for s in rule_heavy],
                frequency=len(rule_heavy) / len(structures) if structures else 0
            ))
        
        if balanced:
            self.patterns.append(Pattern(
                id="pat_struct_balanced",
                name="å¹³è¡¡çµæ§‹",
                description="action å’Œ rule æ¯”ä¾‹å¹³è¡¡çš„ skill",
                pattern_type="structure",
                structure={"type": "balanced"},
                found_in=[s['skill'] for s in balanced],
                frequency=len(balanced) / len(structures) if structures else 0
            ))
    
    def _extract_keyword_patterns(self):
        """å¾æè¿°æ–‡å­—æå–é—œéµå­—æ¨¡å¼"""
        # å¸¸è¦‹å‹•ä½œé—œéµå­—
        action_keywords = [
            ('file_operation', ['è®€å–', 'å¯«å…¥', 'å»ºç«‹', 'åˆªé™¤', 'read', 'write', 'create', 'delete']),
            ('validation', ['é©—è­‰', 'æª¢æŸ¥', 'ç¢ºèª', 'validate', 'check', 'verify']),
            ('transformation', ['è½‰æ›', 'è™•ç†', 'è§£æ', 'convert', 'transform', 'parse']),
            ('output', ['è¼¸å‡º', 'ç”¢ç”Ÿ', 'é¡¯ç¤º', 'output', 'generate', 'display']),
        ]
        
        keyword_matches = defaultdict(list)
        
        for skill in self.skills:
            meta = skill.get('meta', {})
            skill_id = meta.get('skill_id', skill.get('skill_id', skill.get('_source_file')))
            
            # æ”¶é›†æ‰€æœ‰æè¿°æ–‡å­—
            all_text = ""
            
            # æ”¯æ´ v2.0 schema çµæ§‹
            decomposition = skill.get('decomposition', {})
            for elem in decomposition.get('actions', []):
                all_text += elem.get('description', '') + " "
            for elem in decomposition.get('rules', []):
                all_text += elem.get('description', '') + " "
            for elem in decomposition.get('directives', []):
                all_text += elem.get('description', '') + " "
            
            # ä¹Ÿæ”¯æ´èˆŠçš„ elements æ ¼å¼
            for elem in skill.get('elements', []):
                all_text += elem.get('description', '') + " "
            
            all_text = all_text.lower()
            
            # æª¢æŸ¥é—œéµå­—
            for category, keywords in action_keywords:
                for kw in keywords:
                    if kw.lower() in all_text:
                        keyword_matches[category].append(skill_id)
                        break
        
        # å»ºç«‹é—œéµå­—æ¨¡å¼
        for category, skills in keyword_matches.items():
            unique_skills = list(set(skills))
            if unique_skills:
                self.patterns.append(Pattern(
                    id=f"pat_kw_{category}",
                    name=f"é—œéµå­—æ¨¡å¼: {category}",
                    description=f"åŒ…å« {category} ç›¸é—œæ“ä½œçš„ skill",
                    pattern_type="keyword",
                    structure={"category": category},
                    found_in=unique_skills,
                    frequency=len(unique_skills) / len(self.skills) if self.skills else 0
                ))
    
    def save_patterns(self, output_path: str):
        """å„²å­˜æ¨¡å¼åº«"""
        patterns_dict = {
            "version": "1.0",
            "generated_at": datetime.now().isoformat(),
            "total_patterns": len(self.patterns),
            "source_skills_count": len(self.skills),
            "patterns": []
        }
        
        for p in self.patterns:
            patterns_dict["patterns"].append({
                "id": p.id,
                "name": p.name,
                "description": p.description,
                "pattern_type": p.pattern_type,
                "structure": p.structure,
                "found_in": p.found_in,
                "frequency": round(p.frequency, 3),
                "examples": p.examples[:3] if p.examples else []
            })
        
        # ä¾é »ç‡æ’åº
        patterns_dict["patterns"].sort(key=lambda x: -x["frequency"])
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(patterns_dict, f, ensure_ascii=False, indent=2)
    
    def generate_report(self) -> str:
        """ç”¢ç”Ÿæ¨¡å¼å ±å‘Š"""
        lines = [
            "=" * 60,
            "ğŸ” Skill-0 æ¨¡å¼æå–å ±å‘Š",
            "=" * 60,
            f"åˆ†æ Skills æ•¸é‡: {len(self.skills)}",
            f"æå–æ¨¡å¼æ•¸é‡: {len(self.patterns)}",
            "",
        ]
        
        # æŒ‰é¡å‹åˆ†çµ„
        by_type = defaultdict(list)
        for p in self.patterns:
            by_type[p.pattern_type].append(p)
        
        for ptype, patterns in by_type.items():
            lines.append(f"ğŸ“ {ptype.upper()} æ¨¡å¼ ({len(patterns)} å€‹)")
            lines.append("-" * 40)
            
            for p in sorted(patterns, key=lambda x: -x.frequency):
                freq_pct = f"{p.frequency * 100:.0f}%"
                lines.append(f"  [{p.id}] {p.name}")
                lines.append(f"    {p.description}")
                lines.append(f"    å‡ºç¾é »ç‡: {freq_pct}, æ¶µè“‹: {', '.join(p.found_in[:3])}{'...' if len(p.found_in) > 3 else ''}")
                lines.append("")
        
        lines.append("=" * 60)
        return "\n".join(lines)


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Skill-0 æ¨¡å¼æå–å·¥å…·')
    parser.add_argument('--parsed-dir', '-p', default='parsed',
                        help='å·²è§£æ skills çš„ç›®éŒ„ (é è¨­: parsed)')
    parser.add_argument('--output', '-o', default='analysis/patterns.json',
                        help='è¼¸å‡ºæ¨¡å¼åº«è·¯å¾‘ (é è¨­: analysis/patterns.json)')
    
    args = parser.parse_args()
    
    extractor = PatternExtractor(args.parsed_dir)
    
    print(f"ğŸ“‚ è¼‰å…¥ skills å¾: {args.parsed_dir}")
    count = extractor.load_skills()
    print(f"âœ“ è¼‰å…¥ {count} å€‹ skills")
    
    print("ğŸ” æå–æ¨¡å¼...")
    extractor.extract_all_patterns()
    print(f"âœ“ æå– {len(extractor.patterns)} å€‹æ¨¡å¼")
    
    extractor.save_patterns(args.output)
    print(f"âœ“ æ¨¡å¼åº«å·²å„²å­˜: {args.output}")
    
    print("\n" + extractor.generate_report())


if __name__ == '__main__':
    main()
