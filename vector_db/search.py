"""
Semantic Search - èªç¾©æœå°‹ API
æ•´åˆ Embedder å’Œ VectorStoreï¼Œæä¾›å®Œæ•´çš„æœå°‹åŠŸèƒ½
"""

import json
from pathlib import Path
from typing import Dict, List, Optional, Union
import numpy as np

from .embedder import SkillEmbedder
from .vector_store import VectorStore


class SemanticSearch:
    """èªç¾©æœå°‹å¼•æ“"""
    
    def __init__(
        self,
        db_path: Union[str, Path] = 'skills.db',
        model_name: str = 'all-MiniLM-L6-v2'
    ):
        """
        åˆå§‹åŒ–æœå°‹å¼•æ“
        
        Args:
            db_path: å‘é‡è³‡æ–™åº«è·¯å¾‘
            model_name: embedding æ¨¡å‹åç¨±
        """
        self.embedder = SkillEmbedder(model_name)
        self.store = VectorStore(db_path, dimension=self.embedder.dimension)
        
    def index_skills(self, parsed_dir: Union[str, Path], show_progress: bool = True) -> int:
        """
        ç´¢å¼• parsed ç›®éŒ„ä¸­çš„æ‰€æœ‰ skills
        
        Args:
            parsed_dir: parsed/ ç›®éŒ„è·¯å¾‘
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦
            
        Returns:
            int: ç´¢å¼•çš„ skill æ•¸é‡
        """
        skills = self.embedder.load_skills_from_dir(parsed_dir)
        
        if not skills:
            print(f"No skills found in {parsed_dir}")
            return 0
            
        print(f"Embedding {len(skills)} skills...")
        embeddings = self.embedder.embed_skills(skills, show_progress=show_progress)
        
        print(f"Indexing to database...")
        self.store.insert_skills_batch(skills, embeddings)
        
        print(f"âœ“ Indexed {len(skills)} skills")
        return len(skills)
    
    def search(self, query: str, limit: int = 5) -> List[Dict]:
        """
        èªç¾©æœå°‹ skills
        
        Args:
            query: è‡ªç„¶èªè¨€æŸ¥è©¢
            limit: è¿”å›çµæœæ•¸é‡
            
        Returns:
            List[Dict]: åŒ¹é…çš„ skills (å«ç›¸ä¼¼åº¦åˆ†æ•¸)
        """
        query_embedding = self.embedder.embed_query(query)
        results = self.store.search(query_embedding, limit=limit)
        
        # è½‰æ› distance ç‚º similarity (0-1)
        for r in results:
            # sqlite-vec ä½¿ç”¨ L2 è·é›¢ï¼Œè½‰æ›ç‚ºç›¸ä¼¼åº¦
            # è¼ƒå°çš„è·é›¢ = è¼ƒé«˜çš„ç›¸ä¼¼åº¦
            r['similarity'] = 1.0 / (1.0 + r['distance'])
            
        return results
    
    def find_similar(self, skill_name: str, limit: int = 5) -> List[Dict]:
        """
        æ‰¾å‡ºèˆ‡æŒ‡å®š skill ç›¸ä¼¼çš„å…¶ä»– skills
        
        Args:
            skill_name: skill åç¨±
            limit: è¿”å›æ•¸é‡ (ä¸å«è‡ªèº«)
            
        Returns:
            List[Dict]: ç›¸ä¼¼ skills
        """
        # æ‰¾åˆ°æŒ‡å®š skill
        all_skills = self.store.get_all_skills()
        target = None
        for s in all_skills:
            if s['name'].lower() == skill_name.lower():
                target = s
                break
                
        if not target:
            return []
            
        # å–å¾—å‘é‡
        embedding = self.store.get_embedding(target['id'])
        if embedding is None:
            return []
            
        # æœå°‹ç›¸ä¼¼ (å¤šå–ä¸€å€‹å› ç‚ºæœƒåŒ…å«è‡ªèº«)
        results = self.store.search(embedding, limit=limit + 1)
        
        # æ’é™¤è‡ªèº«
        results = [r for r in results if r['id'] != target['id']]
        
        # åŠ å…¥ç›¸ä¼¼åº¦
        for r in results:
            r['similarity'] = 1.0 / (1.0 + r['distance'])
            
        return results[:limit]
    
    def cluster_skills(self, n_clusters: int = 5) -> Dict[int, List[Dict]]:
        """
        å° skills é€²è¡Œèšé¡åˆ†æ
        
        Args:
            n_clusters: èšé¡æ•¸é‡
            
        Returns:
            Dict[int, List[Dict]]: èšé¡çµæœ
        """
        from sklearn.cluster import KMeans
        
        all_skills = self.store.get_all_skills()
        if len(all_skills) < n_clusters:
            n_clusters = len(all_skills)
            
        # æ”¶é›†æ‰€æœ‰å‘é‡
        embeddings = []
        for s in all_skills:
            emb = self.store.get_embedding(s['id'])
            if emb is not None:
                embeddings.append(emb)
            else:
                embeddings.append(np.zeros(self.embedder.dimension))
                
        embeddings = np.array(embeddings)
        
        # K-Means èšé¡
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = kmeans.fit_predict(embeddings)
        
        # çµ„ç¹”çµæœ
        clusters = {}
        for skill, label in zip(all_skills, labels):
            label = int(label)
            if label not in clusters:
                clusters[label] = []
            clusters[label].append(skill)
            
        return clusters
    
    def get_statistics(self) -> Dict:
        """å–å¾—æœå°‹å¼•æ“çµ±è¨ˆ"""
        stats = self.store.get_statistics()
        stats['embedding_dimension'] = self.embedder.dimension
        stats['model_name'] = 'all-MiniLM-L6-v2'
        return stats
    
    def close(self):
        """é—œé–‰é€£ç·š"""
        self.store.close()
        
    def __enter__(self):
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()


def main():
    """CLI å…¥å£"""
    import argparse
    import time
    
    parser = argparse.ArgumentParser(description='Skill-0 Semantic Search')
    parser.add_argument('--db', default='skills.db', help='Database path')
    parser.add_argument('--parsed-dir', default='parsed', help='Parsed skills directory')
    
    subparsers = parser.add_subparsers(dest='command', help='Commands')
    
    # index å­å‘½ä»¤
    index_parser = subparsers.add_parser('index', help='Index skills from parsed directory')
    
    # search å­å‘½ä»¤
    search_parser = subparsers.add_parser('search', help='Search for skills')
    search_parser.add_argument('query', help='Search query')
    search_parser.add_argument('-n', '--limit', type=int, default=5, help='Number of results')
    
    # similar å­å‘½ä»¤
    similar_parser = subparsers.add_parser('similar', help='Find similar skills')
    similar_parser.add_argument('skill_name', help='Skill name to find similar')
    similar_parser.add_argument('-n', '--limit', type=int, default=5, help='Number of results')
    
    # cluster å­å‘½ä»¤
    cluster_parser = subparsers.add_parser('cluster', help='Cluster skills')
    cluster_parser.add_argument('-n', '--clusters', type=int, default=5, help='Number of clusters')
    
    # stats å­å‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='Show statistics')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
        
    search_engine = SemanticSearch(db_path=args.db)
    
    try:
        if args.command == 'index':
            start = time.time()
            count = search_engine.index_skills(args.parsed_dir)
            elapsed = time.time() - start
            print(f"\nâœ“ Indexed {count} skills in {elapsed:.2f}s")
            
        elif args.command == 'search':
            print(f"\nğŸ” Searching for: {args.query}")
            print("-" * 50)
            
            start = time.time()
            results = search_engine.search(args.query, limit=args.limit)
            elapsed = time.time() - start
            
            for i, r in enumerate(results, 1):
                print(f"{i}. {r['name']} ({r['similarity']:.2%})")
                print(f"   Category: {r['category'] or 'N/A'}")
                print(f"   {r['description'][:80]}..." if len(r.get('description', '')) > 80 else f"   {r.get('description', 'N/A')}")
                print()
                
            print(f"Search completed in {elapsed*1000:.1f}ms")
            
        elif args.command == 'similar':
            print(f"\nğŸ”— Finding skills similar to: {args.skill_name}")
            print("-" * 50)
            
            results = search_engine.find_similar(args.skill_name, limit=args.limit)
            
            if not results:
                print(f"Skill '{args.skill_name}' not found")
            else:
                for i, r in enumerate(results, 1):
                    print(f"{i}. {r['name']} ({r['similarity']:.2%})")
                    print(f"   Category: {r['category'] or 'N/A'}")
                    print()
                    
        elif args.command == 'cluster':
            print(f"\nğŸ“Š Clustering skills into {args.clusters} groups...")
            print("-" * 50)
            
            clusters = search_engine.cluster_skills(n_clusters=args.clusters)
            
            for cluster_id, skills in sorted(clusters.items()):
                print(f"\nã€Cluster {cluster_id + 1}ã€‘({len(skills)} skills)")
                for s in skills:
                    print(f"  â€¢ {s['name']}")
                    
        elif args.command == 'stats':
            stats = search_engine.get_statistics()
            print("\nğŸ“ˆ Database Statistics")
            print("-" * 50)
            print(f"Total Skills: {stats['total_skills']}")
            print(f"Total Actions: {stats['total_actions']}")
            print(f"Total Rules: {stats['total_rules']}")
            print(f"Total Directives: {stats['total_directives']}")
            print(f"Embedding Dimension: {stats['embedding_dimension']}")
            print(f"\nCategories:")
            for cat, count in stats['categories'].items():
                print(f"  â€¢ {cat}: {count}")
                
    finally:
        search_engine.close()


if __name__ == '__main__':
    main()
